{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506da36-5815-4479-8df3-d4936ab8bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/09 00:11:22 WARN Utils: Your hostname, Gyro, resolves to a loopback address: 127.0.1.1; using 172.19.134.43 instead (on interface eth0)\n",
      "25/12/09 00:11:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/09 00:11:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, explode\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "import os\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ResumenLibros\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56d9ad-437e-4687-9452-50bb9e2d74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"clean\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5087ba8-0176-480e-9706-fde037a2fddd",
   "metadata": {},
   "source": [
    "### Limpia los nombres de archivo y hace el resumen del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4927a5f-fb43-4030-9114-04257222897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_tfidf = spark.read.parquet(\"tfidf_vectors.parquet\")\n",
    "\n",
    "# Extraer solo el nombre del archivo\n",
    "def extraer_nombre(ruta):\n",
    "    return os.path.basename(ruta).replace(\"%20\", \" \")\n",
    "\n",
    "extraer_nombre_udf = udf(extraer_nombre, StringType())\n",
    "\n",
    "df_tfidf = df_tfidf.withColumn(\"libro\", extraer_nombre_udf(col(\"filename\")))\n",
    "\n",
    "# Función de resumen usando TF-IDF\n",
    "def resumen_libro(libro, top_n=20):\n",
    "    fila = df_tfidf.filter(col(\"libro\") == libro).first()\n",
    "\n",
    "    if fila is None:\n",
    "        return f\"No se encontró el libro '{libro}' en tfidf_vectors.parquet\"\n",
    "\n",
    "    vector = fila.tfidf\n",
    "    valores = vector.toArray().tolist()\n",
    "\n",
    "    indices_ordenados = np.argsort(valores)[::-1][:top_n]\n",
    "\n",
    "    palabras = [f\"feature_{i}\" for i in indices_ordenados]\n",
    "\n",
    "    return \" \".join(palabras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333581e7-ecd2-42ae-8e21-a618c075f8a7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Busca el libro especificado y muestra el resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430c0a15-b55e-4a92-bb00-8c24f585fa35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de 'Dracula.txt' en 20 palabras:\n",
      "feature_795 feature_12193 feature_11925 feature_11150 feature_12401 feature_15273 feature_8229 feature_19556 feature_12322 feature_17588 feature_17703 feature_12502 feature_5363 feature_5782 feature_3057 feature_10552 feature_8500 feature_3100 feature_16464 feature_11521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------                                        \n",
      "Exception occurred during processing of request from ('127.0.0.1', 42002)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.12/socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/robc/SistDist/env/lib/python3.12/site-packages/pyspark/accumulators.py\", line 299, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/robc/SistDist/env/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/home/robc/SistDist/env/lib/python3.12/site-packages/pyspark/accumulators.py\", line 275, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/robc/SistDist/env/lib/python3.12/site-packages/pyspark/serializers.py\", line 597, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "libro_ejemplo = \"Dracula.txt\"\n",
    "\n",
    "resumen = resumen_libro(libro_ejemplo)\n",
    "print(f\"Resumen de '{libro_ejemplo}' en 20 palabras:\")\n",
    "print(resumen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
